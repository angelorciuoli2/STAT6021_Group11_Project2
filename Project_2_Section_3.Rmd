---
title: "Project_2_Section_3"
author: "Maryam"
date: "2025-04-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Section 3: Data Cleaning

This section includes steps to identify and fix data entry errors and transform problematic variables in the King County housing data-set.


## Step 1: Load and Inspect the Data

```{r}
Data <- read.csv("kc_house_data.csv", header = TRUE)
str(Data)
head(Data)
colSums(is.na(Data))
```

## Step 2: Identify Potential Data Entry Errors

In this section, we identify observations that have clearly incorrect or suspicious values. These include homes with 0 or large numbers of bedrooms and bathrooms, 0 square footage, and any unusual pricing or year values.

### 2.1 Bedroom and bathroom check for zero or large Values

We are checking for homes with 0 or large bedrooms and bathrooms.

```{r}

problem_rows <- Data[
  (Data$bedrooms == 0 | Data$bedrooms == 33 | Data$bathrooms == 0) &
  !is.na(Data$bedrooms) & !is.na(Data$bathrooms),
  c("id", "bedrooms", "bathrooms", "sqft_living", "price", "zipcode")
]
problem_rows

```
We identified 16 properties with clearly incorrect or extreme values, including homes with 0 bedrooms, 0 bathrooms, or an unrealistic count of 33 bedrooms. 

### 2.2 Manual Corrections for bedrooms and bathrooms with zero and large values.

```{r}
# 1. 6306400140 – fix bedroom and bathroom 
Data[Data$id == 6306400140, "bedrooms"] <- 5
Data[Data$id == 6306400140, "bathrooms"] <- 4.50

# 2. 3421079032 – fix bedroom and bathroom 
Data[Data$id == 3421079032, "bedrooms"] <- 3
Data[Data$id == 3421079032, "bathrooms"] <- 3.75

# 3. 3918400017 – fix both
Data[Data$id == 3918400017, "bedrooms"] <- 3
Data[Data$id == 3918400017, "bathrooms"] <- 2.25

# 4. 1453602309 – open concept townhome, we verified it has 0 bedroom. (No change needed)

# 5. 6896300380 – fix bedroom only
Data[Data$id == 6896300380, "bedrooms"] <- 3.25

# 6. 5702500050 – remove from dataset (unverifiable)
Data <- Data[Data$id != 5702500050, ]

# 7. 2954400190 – fix bathroom and bedroom
Data[Data$id == 2954400190, "bedrooms"] <- 4
Data[Data$id == 2954400190, "bathrooms"] <- 4

# 8. 2569500210 – fix bedroom only
Data[Data$id == 2569500210, "bedrooms"] <- 4

# 9. 2310060040 – fix bedroom only
Data[Data$id == 2310060040, "bedrooms"] <- 4

# 10. 7849202190 – fix bedroom and bathroom
Data[Data$id == 7849202190, "bedrooms"] <- 3
Data[Data$id == 7849202190, "bathrooms"] <- 1.50

# 11. 203100435 – remove row from data, unable to locate parcel ID
Data <- Data[Data$id != 203100435, ]

# 12. 7849202299 – fix bedroom 
Data[Data$id == 7849202299, "bedrooms"] <- 0

# 13. 9543000205 – fix both
Data[Data$id == 9543000205, "bedrooms"] <- 2
Data[Data$id == 9543000205, "bathrooms"] <- 1

# 14. 2402100895 – was 33 bedrooms, fix to 3
Data[Data$id == 2402100895, "bedrooms"] <- 3

# 15. 1222029077 – fix bedroom and bathroom
Data[Data$id == 1222029077, "bedrooms"] <- 1
Data[Data$id == 1222029077, "bathrooms"] <- 1.50

# 16. 3980300371 – remove (no data found)
Data <- Data[Data$id != 3980300371, ]

# 17. 3374500520 – fix both
Data[Data$id == 3374500520, "bedrooms"] <- 4
Data[Data$id == 3374500520, "bathrooms"] <- 3.5

```


As part of the data cleaning process, we found 17 properties with unusual or clearly incorrect values for bedrooms and bathrooms. Some had 0 bedrooms or 0 bathrooms, and one even had 33 bedrooms, which is obviously unrealistic. Instead of deleting these rows right away, we looked each one up manually using the King County Parcel Viewer to verify what the correct values should be. For most of them, we was able to confirm the actual number of rooms and made the necessary corrections based on that. For instance, one home listed with 0 bedrooms and 0 bathrooms was corrected to 4 bedrooms and 4 bathrooms after verification, and the home listed with 33 bedrooms was updated to 3, which made more sense given its size. One property turned out to be a studio-style layout with 0 bedrooms and 1.5 bathrooms, so we kept that one as-is. In three cases, we couldn’t find any record of the property, and since the information couldn’t be confirmed and looked suspicious, we decided to remove those rows. Overall, this process helped us clean the dataset in a careful and meaningful way, using outside sources to make informed decisions instead of relying only on assumptions or automatic removals.

### 2.3 Living Area and Lot Size Check for Zero

We check for homes with sqft_living == 0 or sqft_lot == 0. A house cannot have 0 square feet of living space or land area.


```{r}
Data[Data$sqft_living == 0 | Data$sqft_lot == 0, ]

```
No homes in the dataset have 0 for sqft_living or sqft_lot



### 2.4 Price Check for Zero or negative

The price variable should always be a positive number. A home with a price of 0 or less is invalid for this dataset, and such rows should be removed.

```{r}
summary(Data$price)
Data[Data$price <= 0, ]

```
There are no homes with a price ≤ 0. There were no such entries, so no cleaning was necessary for this variable.


### 2.5 Year Built & Year Renovated Check for future years
We check for homes with yr_built or yr_renovated in the future (after 2015)

```{r}

Data[Data$yr_built > 2015 | Data$yr_renovated > 2015, ]

```
Dataset has no homes built or renovated after 2015.


## Step 3: Fixing Problematic Variables


### 3.1 Transform date Column

The date column is a character string and not useful for modeling. We'll extract: year and month sold.

```{r}

Data$year_sold <- as.numeric(substr(Data$date, 1, 4))
Data$month_sold <- as.numeric(substr(Data$date, 5, 6))

table(Data$year_sold)
table(Data$month_sold)
```

### 3.2 Transform zipcode to a Factor

zipcode has over 70 unique values. That’s too many for regression modeling, and need 70 dummy variables, which will clutters model and Increases risk of overfitting

```{r}

Data$zip_group <- substr(as.character(Data$zipcode), 1, 3)
table(Data$zip_group)

```

We fixed it by creating a new variable zip_group based on the first 3 digits of the zip code. we've reduced 70+ zip codes into just 2 regional clusters, which; Zip Group "980" has 12,636 homes, and zip Group  "981" has 8,977 homes.


### 3.3 Converting Renovation Year to a Binary Renovation (Yes/No)

```{r}
Data$renovated <- ifelse(Data$yr_renovated > 0, 1, 0)
table(Data$renovated)

```
20,699 homes were not renovated, 914 homes were renovated; which makes sense; most homes dont undergo renovations before being sold 

### 3.4 Transform Latitude & Longitude into Distance to Downtown and compare distance with condition

```{r}

Data$distance_to_downtown <- sqrt(
  (Data$lat - 47.6062)^2 + (Data$long + 122.3321)^2
)

summary(Data$distance_to_downtown)

boxplot(distance_to_downtown ~ condition, 
        data = Data,
        main = "Distance from Downtown vs. Home Condition",
        xlab = "Condition (1 = Poor, 5 = Excellent)",
        ylab = "Distance to Downtown",
        col = "lightblue")


```

The dataset includes latitude and longitude coordinates for each home, but those numbers on their own aren’t easy to interpret or use in a regression model. So instead of trying to include both lat and long as separate variables, I created a new feature called distance_to_downtown. This variable measures how far each home is from downtown Seattle, using the coordinates of Pike Place Market (47.6062, -122.3321) as a reference point. I calculated this using the Euclidean distance formula, which gives us a simple and intuitive way to measure location; homes closer to downtown will have smaller distance values, and those farther away will have higher ones. This new variable helps capture the impact of location on things like price or home quality, in a way that’s much easier to work with than raw coordinates. Based on the summary statistics, most homes are located fairly close to downtown, with a few farther out.


To explore how location might relate to home quality and perceived safety, I used the new variable distance_to_downtown. I then compared this distance to the home’s condition rating, which ranges from 1 (poor) to 5 (excellent). The boxplot shows an interesting pattern: homes with lower condition ratings (1 to 3) tend to be closer to downtown, while those in better condition (ratings 4 and 5) are more commonly located farther away. This suggests that higher-quality homes may be more concentrated in suburban or residential areas, while those in the urban core might be older or less well maintained. Although there’s some overlap between the groups, the trend offers a useful perspective on how distance from the city center could be connected to neighborhood quality or overall housing conditions.


### 3.5 Multicollinearity in Square Footage Variables

```{r}
# Check for multicollinearity among square footage variables
sqft_vars <- Data[, c("sqft_living", "sqft_above", "sqft_basement", "sqft_living15")]
cor_matrix <- round(cor(sqft_vars), 2)
cor_matrix

Data$sqft_above <- NULL
Data$sqft_basement <- NULL
```
The correlation matrix showed that sqft_living is highly correlated with sqft_above (r = 0.88) and also strongly correlated with sqft_living15 (r = 0.76). The relationship between sqft_living and sqft_basement was more moderate (r = 0.43), and there was very little correlation between sqft_above and sqft_basement (r = –0.05).

This makes sense, because sqft_living is generally the total of above- and below-ground finished space. To avoid multicollinearity in our regression models, we chose to retain only sqft_living and exclude sqft_above and sqft_basement. We will re-evaluate sqft_living15 later depending on its impact on the model.

```{r}
write.csv(Data, "kc_house_data_cleaned.csv", row.names = FALSE)

```





